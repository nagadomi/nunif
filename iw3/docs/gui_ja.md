# iw3-gui

iw3-guiはあらゆる画像・動画を3D画像・3D動画に変換するソフトウェアです。
VRで本当に見たかった画像・動画をVRデバイスで3Dメディアとして見れるようになります。

インストールについては[nunif windows package](../../windows_package/docs/README_ja.md)を参照してください。

![iw3-gui-ja](https://github.com/nagadomi/nunif/assets/287255/7e00a886-a9bb-44a4-9168-8851a6ef462f)


このソフトウェアはよい設定値が入力に依存していて調節が難しいソフトウェアです。前半に各項目の説明を記述して、後半に応用的な説明を記述します。

処理の概要は以下です。

- 入力画像（動画フレーム）から深度(各ピクセルの奥行き)を推定します
- 入力画像と推定した深度からステレオ画像(左右それぞれの目に映す画像)を生成します

深度推定には以下の事前学習済みモデルが使用できます。

[ZeoDepth](https://github.com/isl-org/ZoeDepth) or [Depth-Anything](https://github.com/LiheYoung/Depth-Anything) or [Depth-Anything-V2](https://github.com/DepthAnything/Depth-Anything-V2) or [Depth Pro](https://github.com/apple/ml-depth-pro) or [Distill Any Depth](https://github.com/Westlake-AGI-Lab/Distill-Any-Depth).

## 入力

処理対象のファイルまたはフォルダを選択します。最初のボタンが`ファイル選択`で、次のボタンが`フォルダ選択`です。ファイルひとつの場合はドラッグアンドドップもできます。

フォルダを選択した場合はフォルダ直下の画像ファイルと動画ファイルが対象になります。

`処理を再開`にチェックをつけるとすでに出力が存在するファイルをスキップします。

`すべてのサブフォルダを処理`にチェックをつけると指定フォルダより下の階層にあるすべてのファイルが対象になります。ただし出力フォルダ内は除外されます。
指定したフォルダによっては非常に多くのファイルが対象になるので注意してください。

再生ボタンをクリックすると選択したファイルまたはフォルダが表示されます。

## 出力

出力フォルダを選択します。

入力がファイルの場合は出力ファイル名を直接入力することもできます。画像の場合は`.jpg, .png, webp`、動画の場合は`.mp4`の拡張子を使用してください。
またVRで3Dメディアとして認識させるために[ファイル名ルール](#ファイル名ルール)も必要です。

`同じフォルダを設定`ボタンでは、入力と同じフォルダの下に`iw3`フォルダを作ってそこに出力します。

再生ボタンをクリックすると出力結果があればそれを表示します。なければ出力フォルダを表示します。

## ステレオ生成

3D化の設定です。

### 3Dの強さ

奥行きの強さ(深さ)です。

![divergence](https://github.com/nagadomi/nunif/assets/287255/2bf3984e-a125-45f3-bd17-4b16ab467072)

(`--divergence`がこの設定値です)

基本は`2.0`です。


このパラメータは、スクリーン位置の適切な距離を変えます。

低い値では、スクリーン位置の適切な距離は遠くなります。高い値では、スクリーン位置の適切な距離は近くなります。
近くで見たい場合は高い値が適切ですが、高い値ではゴーストアーティファクトが発生しやすくなります。ゴーストアーティファクトは、深度の差が大きいところに発生するノイズのようなものです。人物と背景の境界が2重に見えて焦点が合わせづらくなります。

スクリーン位置はVR動画プレイヤー上のズームイン/ズームアウトで調節できます。

### 収束平面

スクリーンに対する3Dの奥行きが出る位置・方向です。

![convergence](https://github.com/nagadomi/nunif/assets/287255/7d80f540-5f8d-4c6d-86ce-985e524fdea9)

(`--convergence`がこの設定値です)

`0`では、スクリーン位置から前に向かって表示されます。おそらくもっとも一般的な設定です。ただし、スクリーンの端のほうで左右の目で見える範囲が変わるので焦点が合わせづらくなります。

`1`では、スクリーン位置から奥に向かって表示されます。おそらくもっとも問題の発生しない設定です。曲面スクリーンにも適しています。ただし、表示位置が遠くみえます。

`0.5`は、`0`と`1`の中間です。デフォルト値です。

### 自分の大きさ

スクリーンに対する自分の大きさです。

![ipd-offset](https://github.com/nagadomi/nunif/assets/287255/a1001307-8c07-457c-a2a8-f0548e0d072c)

(`--ipd-offset`がこの設定値です)

人物を等身大で見たい等の理由で細かく調節するモチベーションがある場合に調節してください。

VR Player側で設定できる場合もあります。通常は0を選択してください。

### 合成ビュー

`both`では両方の目のビューを生成します。`left`または`right`では片側の目のビューのみを生成します。もう片方の目のビューはオリジナル画像/フレームになります。

`both`を指定した場合、左右の目でアーティファクト/歪みを分散します。それによってアーティファクト自体は軽減しますが、両方の目にアーティファクトが発生する可能性があります。

`left`または`right`を指定した場合は、片方の目はオリジナル画像なのでアーティファクト/歪みは発生しませんが、逆側の目に2倍のアーティファクト/歪みが発生します。
`left`と`right`どちらがいいかは利き目によります。

今のところは、`both`をオススメします。デフォルトは`both`です。

### メソッド

深度からステレオ画像（左右の画像）を生成する手法です。

| Short Name  |                   |
|-------------|-------------------|
| `row_flow_v3`    | 逆方向ワーピング(`grid_sample`)のパラメータを機械学習モデルで算出します。`0.0 <= divergence <= 5.0`の範囲で`forward_fill`で生成した合成データで学習されています。デフォルトメソッド。
| `row_flow_v2`    | 以前のデフォルトメソッド。`0.0 <= divergence <= 2.5`の範囲で[stable-diffusion-webui-depthmap-script](https://github.com/thygate/stable-diffusion-webui-depthmap-script)で生成した合成データで学習されています。
| `forward_fill`   | 深度順の順方向ワーピング（ソース側からのサンプリングは行わず穴は隣接ピクセルで埋める+重なった領域は深度的に前にあるほうで上書き）。非機械学習の率直なメソッド。
| `row_flow_v3_sym`| `row_flow_v3`の左右対称制約版。左と右のワープパラメータは完全に左右対称になります。`row_flow_v3`より2倍速い。実験用。
| `forward`        | 穴を埋めない`forward_fill`。実験用。
| `grid_sample`,`backward`  | 素朴な逆方向ワーピング。ひどいゴーストアーティファクトが発生します。実験用。

### ステレオ処理幅

ステレオ生成を実行する深度画像の解像度(画像の横幅)を指定します。

これはExport/Import時に使用する高度な設定です。通常は、`Default`を選択してください。

`Default`が指定されている場合は、何もしません。
`Default`以外が指定されている場合は、指定サイズに深度画像をリサイズしてから処理します。

Exportした深度画像を別のソフトウェアで処理するときにフレーム画像と画像サイズを合わせることがあり、その場合に深度画像が4Kや8Kになることがあります。iw3のステレオ生成モデルは、深度画像の最大横幅=1920pxで学習されているので、巨大な深度画像をImportすると出力が壊れます。その場合に指定サイズにダウンスケーリングしてから処理するための機能です。
（この制限は深度画像の解像度についてであり、フレーム画像の解像度に制限はありません）

### 深度推定モデル

深度を推定する学習済みモデルを指定します。

深度推定には[ZoeDepth](https://github.com/isl-org/ZoeDepth)または[Depth-Anything](https://github.com/LiheYoung/Depth-Anything)、[Depth-Anything-V2](https://github.com/DepthAnything/Depth-Anything-V2)を使用しています。

| Short Name  |                   |
|-------------|-------------------|
| `ZoeD_N`    | ZoeDepth model NYUv2(屋内シーンのデータ)
| `ZoeD_K`    | ZoeDepth model KITTI(屋外シーンのデータ)
| `ZoeD_NK`   | ZoeDepth model NYUv2 and KITTI
| `ZoeD_Any_N`| Depth-Anything metric depth model NYUv2
| `ZoeD_Any_K`| Depth-Anything metric depth model KITTI
| `Any_S`     | Depth-Anything model small. 一番速い
| `Any_B`     | Depth-Anything model base.
| `Any_L`     | Depth-Anything model large. 精度が高いが重い
| `Any_V2_S`  | Depth-Anything-V2 model small. 一番速いV2
| `Any_V2_B`  | Depth-Anything-V2 model base. (cc-by-nc-4.0)
| `Any_V2_L`  | Depth-Anything-V2 model large. (cc-by-nc-4.0) 深度の精度は一番高い
| `Any_V2_N_S`| Depth-Anything-V2 Metric Depth model Hypersim small. Tuned for indoor scenes.
| `Any_V2_N_B`| Depth-Anything-V2 Metric Depth model Hypersim base. Tuned for indoor scenes
| `Any_V2_N_L`| Depth-Anything-V2 Metric Depth model Hypersim large. Tuned for indoor scenes. (cc-by-nc-4.0)
| `Any_V2_K_S`| Depth-Anything-V2 Metric Depth model VKITTI small. Tuned for outdoor scenes (dashboard camera view).
| `Any_V2_K_B`| Depth-Anything-V2 Metric Depth model VKITTI base. Tuned for outdoor scenes (dashboard camera view).
| `Any_V2_K_L`| Depth-Anything-V2 Metric Depth model VKITTI large. Tuned for outdoor scenes (dashboard camera view). (cc-by-nc-4.0)
| `DepthPro`  | Depth Pro model. 1536x1536 resolution. For image use.
| `DepthPro_S`  | Depth Pro model. 1024x1024 modified resolution. For image use.
| `Distill_Any_S`  | Distill Any Depth model small.
| `Distill_Any_B`  | Distill Any Depth model base.
| `Distill_Any_L`  | Distill Any Depth model large.


通常は`ZoeD_N`か`Any_B`,または`ZoeD_Any_N`を選択してください。

`ZoeD_N`は屋内シーンのデータで調節されたモデルです。`ZoeD_K`は、屋外シーンのデータで調節されたモデルですが、屋外シーンというのがドライブレコーダーの映像です（これが向いているケースはないと思います）。

`Any_B`はDepthAnythingの基本モデルです。`Any_S`が速くて精度が低い、`Any_L`が遅くて精度が高いバランスのモデルです。

`ZoeD_Any_N`は、`ZoeD_N`のバックボーンを`Any_L`にして学習されたモデルです。3Dシーンの生成結果は最もよいと思います。

DepthAnythingのほうが精度が高いですが、ステレオ生成の結果はZoeDepthのほうがよいことが多いです。DepthAnythingのほうが使用VRAMが少なく速いです。

イラスト/アニメには、ZoeDepthよりもDepthAnythingのほうがよいです。`Any_V2_L`がよいですが、デフォルトでは利用できないので自分で配置する必要があります。

またZoeDepthとDepthAnythingは出力する深度の種類が違います。ZeoDepthはメートル単位の距離を出力していて、DepthAnythingはDisparity(視差)を出力しています。近い結果に見えるように変換式を調節していますが、モデルを変更すると深度の精度だけではなく他の設定の見え方も全体的に変わることに注意してください。

たくさんありますが、個人的には、`ZoeD_N`, `Any_B`, `ZoeD_Any_N`のどれかをオススメします。

### `Any_V2_B` ,`Any_V2_L`, `Any_V2_N_L`, `Any_V2_K_L` について

これらのモデルはcc-by-nc-4.0(非商用)の下で配布されています。nunifのMITライセンスと衝突するためデフォルトでは利用できません。

使用したい場合は、それらのライセンスに同意して自分でファイルを配置してください。

| Short Name | ファイル |
|------------|------|
| `Any_V2_B` | `iw3/pretrained_models/hub/checkpoints/depth_anything_v2_vitb.pth`
| `Any_V2_L` | `iw3/pretrained_models/hub/checkpoints/depth_anything_v2_vitl.pth`
| `Any_V2_N_L` | `iw3/pretrained_models/hub/checkpoints/depth_anything_v2_metric_hypersim_vitl.pth`
| `Any_V2_K_L` | `iw3/pretrained_models/hub/checkpoints/depth_anything_v2_metric_vkitti_vitl.pth`

これらのファイルは https://huggingface.co/depth-anything のModelsセクションからダウンロードできます。開いたページの`Files and versions`タブにあります。
ファイルが存在する場合のみGUI上に表示されます。

### `Distill_Any_B`, `Distill_Any_L` について

これらのモデルはApache License 2.0とされていますが、cc-by-nc-4.0(非商用)であるDepth-Anythin V2を初期重みとして使用しています。

使用したい場合は、自分でファイルを配置してください。

| Short Name | ファイル |
|------------|------|
| `Distill_Any_B` | `iw3/pretrained_models/hub/checkpoints/distill_any_depth_vitb.safetensors`
| `Distill_Any_L` | `iw3/pretrained_models/hub/checkpoints/distill_any_depth_vitl.safetensors`

これらのファイルは https://github.com/Westlake-AGI-Lab/Distill-Any-Depth のPre-trained Modelセクションからダウンロードできます。

これらのファイルは`.safetensors`形式です。`.pth`への変換は必要ありませんが、上記のファイル名にリネームする必要があります。

### 深度解像度

深度推定時の解像度を上げることができます。解像度が高いほど処理時間がかかります。

ZoeDepthモデルでは、モデル自体が高解像度に対応していないため、結果がよくなるかは分かりません。縦長の画像はデフォルトで大きめの解像度で計算されているので効果はありません。

DepthAnythingモデルでは512(518)で適切な解像度になり深度の精度が上がります。

### 前景拡大

正の値で、遠くほど立体感をなくしてその分の立体感を近い方に割り当てます。(背景の厚みを縮小して前景の厚みを拡大します)

![foreground-scale](https://github.com/nagadomi/nunif/assets/287255/5664ea7a-bcf8-4430-b490-7f2bcf1a81c4)

屋外写真で前景(人物)の奥行きが圧縮されて平面に見える場合は`3`を試してみてください。動画では`0`をオススメします。


負の値では、逆の効果になります。背景が激しく揺れ動くことがあるので動画ではオススメはしません。

![foreground-scale-negative](https://github.com/nagadomi/nunif/assets/287255/458ca299-fb23-4e8d-b530-c7a3fe17dee3)

### 境界修正

この設定はDepthAnythingモデルでのみ有効になります。チェックをつけると`ZoeD_Any_N`でも使用できます。

DepthAnythingの出力は精度が高いですが、ステレオ生成においては前景と背景の境界に歪みやアーティファクトが発生しやすくなります。このアプローチでは、前景側のセグメントを膨張させることでその問題を軽減します（歪む領域が前景から背景に移動します）。

![edge-dilation](https://github.com/nagadomi/nunif/assets/287255/cb67b93a-bf26-4ea2-ac8b-418d5dc716c3)

0では無効になります。2がデフォルトです。4はもっとも目に優しい結果になりますが深度の解像度が落ちます。

### フォーマット

出力形式を指定します。またVR動画プレイヤーにメディアの形式を認識させるためにファイル名にそれぞれ識別子を追加します。[ファイル名ルール](#ファイル名ルール)

`Full SBS`は、フル解像度のサイド・バイ・サイドです。

`Half SBS`は、ハーフ解像度のサイド・バイ・サイドです。画像の横幅が半分に圧縮されます。古いVR機器ではこのフォーマットしかサポートしていないことがあります。

`Full TB`,`Half TB`はトップ・ボトムです。3DTV(Polarized/Passive 3D system)では、トップ・ボトムのほうがサイド・バイ・サイドよりも高い解像度で再生できることがあります。

`VR90`は、正面90°のみを描画したVR180フォーマット(Equirectangular)です。再生時の操作が制限されるので通常はオススメしません。使用しているVR機器や投稿サイト等の都合で使いたい場合に指定してください。Youtubeのメタデータ設定は https://github.com/nagadomi/nunif/issues/268 を見てください。

`Cross Eyed`は交差法用のSBSです。専用デバイスがなくても寄り目で画像を重ねると立体に見えます。通常のSBSと左右の画像が逆になっています。

`Anaglyph *`は、Red-Cyan Anaglyph 3D formatです。

`Export`と`Export Disparity`は、深度画像とフレーム画像を画像シーケンスとして出力/再入力する機能です。詳しくは https://github.com/nagadomi/nunif/issues/97#issuecomment-2027349722 を見てください。

### ちらつきを軽減

フレーム間での深度のちらつきを減らします。個人的には、違いが分からないのと副作用もあるのででオススメしませんが、目がよくて深度のちらつきが気になることがあれば試してみてください。動画のみに影響します。

## 背景除去

背景を除去した画像から深度を推定します。

屋外シーン等で人物が平面に見える場合に使用すると修正できる場合があります。写真に対して細かく設定を調節するモチベーションがあるときに使用してみてください。

## 動画圧縮

動画出力時の設定です。主にlibx264の設定です。
より詳しい情報は https://trac.ffmpeg.org/wiki/Encode/H.264 を参照してください。

### 最大フレームレート

動画のフレームレート(一秒間のフレーム数)が最大フレームレートを超えているときは最大フレームレートに制限します。
超えていないときはオリジナルの（平均）フレームレートで出力します。

デフォルトで30FPSに制限されていることに注意してください。

60FPS動画の処理には30FPS制限の2倍の処理時間がかかることにも注意してください。

### ピクセルフォーマット

出力動画のピクセルフォーマットを指定します。通常は`yuv420p`を指定してください。
詳しい人は他の設定も使えます。`色空間`とも関連しています。

### 動画形式

コンテナ形式を指定します。

`mp4`は互換性の高い形式です。

`mkv`は変換中に視聴できます。変換速度が30FPSを超えていればリアルタイムで視聴できます（シークは変換済み範囲しかできません）。

`avi`はロスレス動画用に用意しています。自分で再エンコードする場合などに指定します。

### 動画コーデック

`libx264`はH.264用です。互換性の高い形式です。4Kなどの大きい動画ではファイルサイズ/ビットレートが大きくなり、再生に問題が起こることがあります。

`libx265`はH.265用です。通常はH.264よりもファイルサイズが小さくなります。ただし古い機器では対応していないことがあります。

`utvideo`はロスレス動画コーデックです。再生には[Ut Video Codec Suite](https://github.com/umezawatakeshi/utvideo/releases)のインストールが必要かもしれません。

`h264_nvenc`, `hevc_nvenc`(H.265)は、NVIDIAのハードウェアエンコーダーです。

ffmpegが対応しているコーデックを直接指定することもできますが、追加のオプションが指定できないのでうまく使えないかもしれません。

### 色空間

出力動画のYUVカラースペースとダイナミックレンジを指定します。

詳細は[色空間について](colorspace_ja.md)を参照してください。

### CRF

品質設定です。**小さい値**ほど品質が高くファイルサイズが大きくなります。0など選択より小さい値を直接入力することもできます。

### レベル

H.264/H.265のレベルを指定できます。通常は`auto`をオススメします。

libx264では単にメタデータを設定するだけだと思います。

libx265ではより厳密でレベルの範囲外のサイズの動画に対して誤ったレベルを指定するとエラーになります。

関連するプロファイルに関しては、現在使っているライブラリの関係で指定する方法がありません。
ただ、`libx264`では、`preset=ultrafast`のときに`Constrained Baseline`になり、`preset=ultrafast`以外では`High`になるようです。

### プリセット

処理速度と圧縮率のバランスを決めるオプションです。
遅い設定のほうが圧縮率が高くファイルサイズが小さくなります。

高解像度の動画にslower,veryslow,placeboを使用するとハードウェアデコーダーで正常に再生できない（ひどいアーティファクトが発生する）動画が生成されることがあるようです。
slowより遅い設定は使わないのが安全です。`medium`をオススメします。

### チューニング

入力にあった設定のセットを使用できます。

- `animation`: アニメ
- `film`: 映画 実写
- `stillimage`: スライドショー
- `grain`: アナログフィルム (粒子状ノイズの維持）
- `fastdecode`: いくつかのフィルタを無効にすることで再生時の負荷を減らします
- `zerolatency`: シークが速くなります。

よくわからない場合は選択しません。

## ビデオフィルタ

動画の追加処理です。

### 開始時間, 終了時間

入力動画内の処理する時間範囲を指定します。指定された時間範囲のみ出力します。
チェックを付けなければすべて処理されます。

### デインターレース

入力ストリームに対してデインターレースフィルタを適用します。インターレース方式の動画に使用します。
（動画に細かい横線が点滅するやつを消します）

現在は、yadifが選択できます。
他のフィルタやより高度なオプションを使いたい場合は、下記のvfオプションを使用してください。

## vf

入力動画ストリームに対してffmpegのビデオフィルター(-vfオプション)を適用します。この処理は深度推定よりも前に適用されます。

ブランチを含む複雑な式は動作しません。`フィルタ名1,フィルタ名2=パラメータ1:パラメータ2,...`形式の直列な式のみ対応しています。パラメータ内の`,`は`\,`にエスケープしてください。
式の解析が独自実装なのでうまくいかない式があるかもしれません。

## 回転

入力フレームを90°回転させます。スマホで撮影した動画など横向きになっている動画を処理前に修正する機能です。

## パディング

出力フレーム内に黒の余白を追加します。通常はオススメしません。
人物サイズやスクリーンの表示位置など細かく調節したい場合に使用してください。

## 出力サイズ制限

出力サイズを指定解像度内に制限します。スマホを使ったCardboard(安価なVRメガネ)で、解像度の大きい動画が再生できない場合に使用してください。

`アスペクト比を維持`にチェックがない場合は、指定されたサイズにフィットするようにリサイズします。VRプレイヤー側でアスペクト比を修正できる場合にチェックを外します。

## プロセッサ

計算に関連する設定です。

### デバイス

計算に使用するGPUまたはCPUを指定します。

GPUにはCUDAに対応しているグラフィックボードが表示されます。事実上NVIDIA製になります。

CPUでも動作はしますが、信じがたい遅さになります。

### 深度バッチサイズ

深度推定を同時に処理するフレーム数です。主に動画用です。画像は1フレームなので基本的には1で処理されます（TTAを使ったときは最大で2になります）。

一般的には、大きい値ほど多くのVRAM(グラフィックボードのメモリ)を使用して処理が速くなります。環境によっては小さい値のほうが速いこともあります。

VRAMが少ないGPUでは小さい値にしないとメモリ不足エラーになります。

### ワーカースレッド

0以外で深度推定とステレオ生成をスレッドプール上で行います。

一般的には、デフォルトの0よりも2が速いです。ただし0以外にするとVRAM使用量が増えます。その分、深度バッチサイズを小さくする必要があるかもしれません。

Windowsや遅いディスクの環境では、小さいバッチサイズに大きいワーカースレッド数が速いことがあります。

### 低ビデオメモリ

すべての条件下で深度バッチサイズを1に制限にします。どうやってもVRAMのメモリ不足になる場合に試してみてください。

### TTA

深度推定を左右反転してた2パターンの画像に対して行い結果を平均して品質を改善します。ただし処理時間が2倍になります。

### FP16

計算に半精度浮動小数点(16bit float)を使用します。
Turing(RTX20シリーズ)以降のGPUでは有効にすることで処理が速くなりVRAMの使用量が減ります。

古いGPUでは遅くなったりエラーになったりするかもしれません。その場合はOFFにできます。

## 開始・キャンセル

`開始`ボタンで処理を開始します。`キャンセル`ボタンで実行中の処理をキャンセルします。

# 応用

## VR動画プレイヤー

Meta Quest 2上の以下の2つのソフトウェアで動作確認しています。

### Pigasus VR Media Player

Pigasusは、3D動画、3D画像、SMB(共有ドライブ)すべてで完璧に動作します。
ただし、個人的にはUIや操作があまり好きではありません。

### SKYBOX VR Video Player

最近の更新でFull SBSの大体の機能は動作するようになりました。
まだ以下の機能はありません。

- 画像の送りがコントローラーでできません

スクリーン位置を調節するには、シネマシーン設定で`VOID`を設定してください。 (`Cinema Scene > SELECT THEATER > VOID`)

## ファイル名ルール

VR動画プレイヤーはファイル名によってメディアの形式を認識しています。

ファイル名の末尾に以下の識別子をつけると正しいフォーマットで認識されます。

- `_LRF_Full_SBS`: Full SBS
- `_LR`: Half SBS
- `_180x180_LR`: VR180 (VR90)

出力にフォルダを指定した場合、上記の識別子が自動で追加されます。ファイル名を直接指定する場合は、手動で追加してください。

参考:
- Pigasusでは `LRF` が必要 https://hanginghatstudios.com/pigasus-faq/#acc-tb_obg1300-0
- SKYBOXでは `Full_SBS` が必要, https://forum.skybox.xyz/d/2161-skybox-vr-quest-v116-added-multi-language-keyboard-and-casting
- DeoVRでは `SBS` か `LR`(`LRF` は動作しない)が必要, https://deovr.com/app/doc#naming

`_LRF_Full_SBS`は上記のソフト全てで動作します。

SKYBOXは何か別の条件(ファイル名が長すぎる?)で認識しないことがあります。その場合はメニューから`3D Full-SBS Matching`を有効にできます。

## トラブルシューティング

## 出力動画がSBSになっていない

Windows Photoなどいくつかのソフトウェアはサイドバイサイドの片側だけを表示します。
他の動画プレイヤーで確認してみてください。

（表示上だけの問題です）

### 前景(人物)が平面になる

屋外シーンの写真で発生しやすいです。

この問題と戦ういくつかの方法があります。

- `前景拡大`を`3`にする
- `背景除去`を有効にする
- それらの組み合わせ

この問題の原因のひとつは、iw3ではあらゆるシーンを同じ厚さ内に表示していることです。
壁まで2メートルのシーンと空が宇宙まで続いているシーンでは、人物の厚みに使える範囲が大きく変わります。
iw3では、遠くほど厚みを無くしてその分を近くに割り当てることでこの問題を軽減していますが、汎用的な設定では限界があります。

`前景拡大`の値を上げるほど、遠くほど厚みをなくしてその分を近くに割り当てます。

`背景除去`を行うと背景の距離が無くなるのでうまくいけば距離の問題が完全に解決します。ただし背景除去の精度の問題があり、複雑なシーンでは人物の切り抜きがうまくいきません。何が前景で何が背景なのかという問題もあります。

### 動画エンコード・デコードエラー

フォーマットをissueに投稿してもらえれば解決できるかもしれません。
単純にファイルが壊れている場合は、他の方法で修正してください。

### 巨人!!

これはSBS 3D動画では原寸大を表現できないという根本的な問題です。

写真やシーンが動かない動画では、手動でサイズ感を調節できます。

- VR動画プレイヤーの設定で調節
- `自分の大きさ`で調節
- `パディング`で調節
- 組み合わせ

SKYBOX Playerでは、`3D Effect`を-0.3などマイナス側に動かすと対象が小さく見えます。

Pigasusでは、`設定 > 高度な設定 > IPD`のスライダーを大きくすると対象が小さく見えます。またトリガーボタンをダブルクリックすると画像内の一部を拡大・移動できます。

`自分の大きさ`設定では、それらよりも更に小さくできます。
ただし、小さくするほど厚みがなくなります。この場合、`3Dの強さ`を大きくできますが、大きくしぎるとゴーストアーティファクトが発生します。

また曲面スクリーンを使っているとサイズが大きく見えるので注意してください。

また`収束平面`が`0`と`1`では大きさの見え方も変わるので注意してください。`1`のほうが大きく見えます。

### CUDA Out of Memory

GPUのメモリ不足です。`深度バッチサイズ`を小さくするか`低VRAM`を有効にしてみてください。

また一度のこのエラーになると再度発生しやすくなるかもしれません。一度プログラムを終了してみてください。

作者はこのソフトウェアをRTX 3070 Ti(8GB VRAM, Linux)とGTX 1050 Ti(4GB VRAM, ノートPC, Windows)で動作確認していますが、どちらもデフォルトの設定で動作しています。

ちなみに上記の環境では、RTX 3070 TiのマシンがGTX 1050 Tiのマシンの10倍速いので、もしこのソフトウェアを気に入って古いGPUを使っている場合はRTX 3070 Ti以上の購入をオススメします。10時間かかる動画変換処理が1時間で終わるかもしれません。（OSや本体の違いもあるので言い切ることはできません）

### NVENC(`h264_nvenc` `hevc_nvenc`)が動作しない

NVIDIA Driver 570 以降をインストールしてください。

## サブプロジェクト

[iw3-desktop](desktop_ja.md) はPCのデスクトップ画面を3D変換してWiFi経由でストリーミング配信するツールです。
